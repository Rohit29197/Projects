{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import ttk, filedialog\n",
    "from tkinter.filedialog import askopenfile\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from skimage import io, img_as_float\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('TKAgg')\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.figure import Figure\n",
    "from skimage.filters import threshold_multiotsu\n",
    "from scipy import ndimage as nd\n",
    "from PIL import ImageTk,Image \n",
    "from scipy import ndimage\n",
    "from skimage import measure, color, io\n",
    "import cv2\n",
    "from matplotlib import figure\n",
    "from skimage import measure, io, img_as_ubyte\n",
    "from skimage.color import label2rgb, rgb2gray\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "class segmentation(Tk):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set the geometry of tkinter frame\n",
    "        (self.geometry(\"700x350\"))\n",
    "\n",
    "        ttk.Button(self, text=\"Select_Images for segmentation\", command=self.main_image).place(x = 10, y = 10)\n",
    "        # select the image that needs to be segment (multiple or single image can be select)\n",
    "        ttk.Button(self, text=\"Reference Image\", command=self.reference_image).place(x = 215, y= 10)\n",
    "        # select the unskewed image that will unskewed the original image (only single image can be select)\n",
    "        \n",
    "        ttk.Button(self, text=\"Region of interest\", command=self.region_image).place(x = 340, y= 10)\n",
    "        # select the region of interest image that will detect the same region in the original (only single image can be select)\n",
    "        \n",
    "        self.filter_button() # filters option\n",
    "        self.K_value() # to segment the image in k number of clusters \n",
    "        self.segmentation_button() # options for different segment algorithm \n",
    "        self.watershed_values() # algorithm for closing the open voids \n",
    "\n",
    "\n",
    "    def main_image(self):\n",
    "       self.image = filedialog.askopenfilenames(initialdir=\"/\", title=\"Select A File\", filetypes=((\"jpg files\", \"*.jpg\"),(\"all files\", \"*.*\"))) \n",
    "        # button to select the image for segmentation\n",
    "    def reference_image(self):\n",
    "       self.ref_image = filedialog.askopenfilename(initialdir=\"/\", title=\"Select A File\", filetypes=((\"jpg files\", \"*.jpg\"),(\"all files\", \"*.*\")))\n",
    "       # button to select the unskewed image \n",
    "       self.rotation() # algorithm for unskewed the original image  \n",
    "    def region_image(self):\n",
    "      self.filename = filedialog.askopenfilename(initialdir=\"/\", title=\"Select A File\", filetypes=((\"jpg files\", \"*.jpg\"),(\"all files\", \"*.*\")))\n",
    "      # button to select the region of interest image \n",
    "        \n",
    "      self.Region_of_interest() # algorithm to detect the region of interest in the original \n",
    "\n",
    "    def rotation (self):     \n",
    "\n",
    "           self.unskewed_image=[]      \n",
    "           for i in self.image: # iterate over the original images\n",
    "\n",
    "                im1 = cv.imread(i,0)  # skewed image       \n",
    "                im2 = cv.imread(self.ref_image,0)# reference image\n",
    "\n",
    "                img1=im1.copy()\n",
    "                img2=im2.copy()\n",
    "\n",
    "                \n",
    "                MIN_MATCHES = 2 # minimum number of matches should be between the skewed image and reference image \n",
    "                \n",
    "                # Initiate ORB detector\n",
    "                orb = cv.ORB_create(nfeatures=500)#Registration works with at least 500 points\n",
    "                \n",
    "                # find the keypoints and descriptors with orb\n",
    "                kp1, des1 = orb.detectAndCompute(img1, None) #kp1 --> list of keypoints\n",
    "                kp2, des2 = orb.detectAndCompute(img2, None) #kp2 --> list of keypoints\n",
    "                \n",
    "                index_params = dict(algorithm=6,\n",
    "                                    table_number=6,\n",
    "                                    key_size=12,             # algorithm parameters\n",
    "                                    multi_probe_level=2)\n",
    "                search_params = {}\n",
    "                flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "                matches = flann.knnMatch(des1, des2, k=3)\n",
    "\n",
    "                # As per Lowe's ratio test to filter good matches\n",
    "                good_matches = []\n",
    "                for m, n, k in matches:\n",
    "                    if m.distance < 0.75 * n.distance:\n",
    "                        good_matches.append(m)\n",
    "\n",
    "                if len(good_matches) > MIN_MATCHES:\n",
    "                    src_points = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "                    dst_points = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "                    m, mask = cv.findHomography(src_points, dst_points, cv.RANSAC, 5.0)\n",
    "                    corrected_img = cv2.warpPerspective(img1, m, (img2.shape[1], img2.shape[0]),flags=cv2.INTER_LINEAR)\n",
    "                angle = - math.atan2(m[0,1], m[0,0]) * 180 / math.pi\n",
    "                if angle < -45:\n",
    "                        angle = -(90 + angle)\n",
    "                        # otherwise, just take the inverse of the angle to make it positive\n",
    "                        \n",
    "                else:\n",
    "                    angle = -angle\n",
    "                (h, w) = im2.shape[:2]\n",
    "                center = (w // 2, h // 2)\n",
    "                M = cv.getRotationMatrix2D(center, angle, 1.0)\n",
    "                rotated = cv.warpAffine(img1, M, (w, h),\n",
    "                    flags=cv.INTER_CUBIC, borderMode=cv.BORDER_REPLICATE)\n",
    "                \n",
    "                self.unskewed_image.append(rotated)\n",
    "                \n",
    "                if ((i==self.image[0]).all()):\n",
    "                        cv2.imshow('original_image', im1)\n",
    "                        cv2.imshow('Corrected image', rotated)\n",
    "                        cv2.waitKey(0)\n",
    "                        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    def Region_of_interest(self):\n",
    "\n",
    "\n",
    "            def template_matching(img2,template):\n",
    "                w, h = template.shape[::-1]\n",
    "                # All the 6 methods for comparison in a list\n",
    "                #methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR','cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "                methods = [ 'cv.TM_SQDIFF_NORMED']\n",
    "                for meth in methods:\n",
    "                    self.img = img2.copy()\n",
    "                    method = eval(meth)\n",
    "                    # Apply template Matching\n",
    "                    res = cv2.matchTemplate(self.img,template,method)\n",
    "                    # For TM_SQDIFF, Good match yields minimum value; bad match yields large values\n",
    "                    # For all others it is exactly opposite, max value = good fit.\n",
    "                    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "                    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "                    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "                                top_left = min_loc\n",
    "                    else:\n",
    "                        top_left = max_loc #Change to max_loc for all except for TM_SQDIFF\n",
    "                    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "                    # Prepare crop area\n",
    "                    width, height = bottom_right[0]-top_left[0], bottom_right[1]-top_left[1]\n",
    "                    x, y = top_left[0], top_left[1]\n",
    "                    # Crop image to specified area using slicing\n",
    "                    self.crop_img = self.img[y:y+height, x:x+width]\n",
    "                    # Show image\n",
    "                    \n",
    "                    cv.imshow(\"cropped\", self.crop_img)               \n",
    "                    cv.waitKey(0)\n",
    "                    cv.destroyAllWindows()\n",
    "                    return self.crop_img\n",
    "                    \n",
    "                    \n",
    "#                     try:\n",
    "#                         if ((img2==self.image[0]).all()):\n",
    "#                             cv.imshow(\"cropped\", self.crop_img)               \n",
    "#                             cv.waitKey(0)\n",
    "#                             cv.destroyAllWindows()\n",
    "#                         return self.crop_img\n",
    "                    \n",
    "#                     except AttributeError: \n",
    "#                             if ((img2==self.unskewed_image[0]).all()):\n",
    "#                                 cv.imshow(\"cropped\", self.crop_img)\n",
    "#                                 cv.waitKey(0)\n",
    "#                                 cv.destroyAllWindows()\n",
    "#                             return self.crop_img\n",
    "\n",
    "            try:\n",
    "                self.region=[]\n",
    "                for i in self.image:\n",
    "                    img2 =  cv.imread(i,0)\n",
    "                    template = cv.imread(self.filename,0)\n",
    "                    matching_region= template_matching(img2,template)\n",
    "                    self.region.append(matching_region)\n",
    "\n",
    "            except AttributeError:\n",
    "                self.region=[]\n",
    "                for i in self.unskewed_image:\n",
    "                    img2 = cv.imread(i,0) \n",
    "                    template = cv.imread(self.filename,0)\n",
    "                    matching_region=template_matching(img2,template)\n",
    "                    self.region.append(matching_region)\n",
    "\n",
    "\n",
    "    def filter_button(self):\n",
    "\n",
    "            def callback(event):\n",
    "\n",
    "                  if self.comboExample.get() =='circle_detection': \n",
    "                                self.circle_pop()\n",
    "\n",
    "                  if self.comboExample.get() == 'Blurr_filter':\n",
    "                        self.gaussian()\n",
    "\n",
    "                  if self.comboExample.get() == 'sharp':\n",
    "                        self.sharp()\n",
    "\n",
    "\n",
    "            self.labelTop = tk.Label(self,\n",
    "                            text = \"Choose the filter \")\n",
    "\n",
    "            self.labelTop.place(x=470,y=10)\n",
    "            self.comboExample = ttk.Combobox(self, \n",
    "                                    values=[\n",
    "                                            \"circle_detection\", \n",
    "                                            \"Blurr_filter\",\n",
    "                                            \"sharp\",\n",
    "                                            ])\n",
    "            self.comboExample.place(x=470,y=30)\n",
    "\n",
    "            self.comboExample.bind(\"<<ComboboxSelected>>\", callback)\n",
    "\n",
    "    def calculation(self):\n",
    "\n",
    "            self.circle=[]\n",
    "            for i in self.region:\n",
    "                self.image=i.copy()\n",
    "                circles = cv.HoughCircles(self.image, cv.HOUGH_GRADIENT,float(self.a.get()),int(self.b.get()),int(self.c.get()),int(self.d.get()))\n",
    "                detected_circles = np.uint16(np.around(circles))\n",
    "                for (x, y, r) in detected_circles[0,:]:\n",
    "                    cv.circle(self.image, (x,y), int(r)+int(self.g.get()),255,-1)\n",
    "                self.circle.append(self.image)\n",
    "                \n",
    "                #if ((self.image==self.region[0]).all()):\n",
    "                cv.imshow('output',self.image)\n",
    "                cv.waitKey(0)\n",
    "                cv.destroyAllWindows()\n",
    "            self.top.destroy()\n",
    "\n",
    "\n",
    "    def circle_pop(self):\n",
    "\n",
    "    #Create a Toplevel window\n",
    "        self.top= Toplevel(self)\n",
    "        self.top.geometry(\"400x400\")\n",
    "\n",
    "        Label(self.top, text=\"Enter inverse ratio of accumulator resolution and image resolution\", font=('Calibri 10')).pack()\n",
    "        self.a=Entry(self.top, width=35)\n",
    "        self.a.insert(0, float(1.67))\n",
    "        self.a.pack()\n",
    "\n",
    "        Label(self.top, text=\"Enter Minimum_Distance\", font=('Calibri 10')).pack()\n",
    "        self.b=Entry(self.top, width=35)\n",
    "        self.b.insert(0, int(50))\n",
    "        self.b.pack()\n",
    "\n",
    "        Label(self.top, text=\"Enter  Parameter_1\", font=('Calibri 10')).pack()\n",
    "        self.c=Entry(self.top, width=35)\n",
    "        self.c.insert(0, int(100))\n",
    "        self.c.pack()\n",
    "\n",
    "        Label(self.top, text=\"Enter  Parameter_2\", font=('Calibri 10')).pack()\n",
    "        self.d=Entry(self.top, width=35)\n",
    "        self.d.insert(0, int(50))\n",
    "        self.d.pack()\n",
    "\n",
    "\n",
    "        Label(self.top, text=\"Enter  additional radius for circle\", font=('Calibri 10')).pack()\n",
    "        self.g=Entry(self.top, width=35)\n",
    "        self.g.insert(0, int(22))\n",
    "        self.g.pack()\n",
    "\n",
    "\n",
    "\n",
    "        self.button= Button(self.top, text=\"Ok\", command=self.calculation)\n",
    "        self.button.pack(pady=5, side= TOP)\n",
    "\n",
    "    def cal (self):\n",
    "        self.blurr=[]\n",
    "        for i in self.region:\n",
    "            img=i.copy()\n",
    "            self.denoise_img = denoise_tv_chambolle(img, weight=float(self.a.get()), eps=float(self.b.get()), n_iter_max=int(self.c.get()), multichannel=False)\n",
    "            self.blurr.append(self.denoise_img)\n",
    "            \"\"\"\n",
    "            denoise_tv_chambolle(image, weight=0.1, eps=0.0002, n_iter_max=200, multichannel=False)\n",
    "            weight: The greater weight, the more denoising (at the expense of fidelity to input).\n",
    "            eps: Relative difference of the value of the cost function that determines the stop criterion. \n",
    "            n_iter_max: Max number of iterations used for optimization\n",
    "            \"\"\"\n",
    "\n",
    "            cv.imshow('output',self.denoise_img)\n",
    "            cv.waitKey(0)\n",
    "            cv.destroyAllWindows()\n",
    "        self.pop.destroy()\n",
    "\n",
    "    def gaussian(self):\n",
    "\n",
    "        self.pop= Toplevel(self)\n",
    "        self.pop.geometry(\"400x400\")\n",
    "\n",
    "        Label(self.pop, text=\"Enter weight\", font=('Calibri 10')).pack()\n",
    "        self.a=Entry(self.pop, width=35)\n",
    "        self.a.insert(0, float(0.015))\n",
    "        self.a.pack()\n",
    "\n",
    "        Label(self.pop, text=\"Enter number of eps\", font=('Calibri 10')).pack()\n",
    "        self.b=Entry(self.pop, width=35)\n",
    "        self.b.insert(0, float(0.0005))\n",
    "        self.b.pack()\n",
    "\n",
    "        Label(self.pop, text=\"Enter number of iteration\", font=('Calibri 10')).pack()\n",
    "        self.c=Entry(self.pop, width=35)\n",
    "        self.c.insert(0, int(200))\n",
    "        self.c.pack()\n",
    "\n",
    "\n",
    "        self.button= Button(self.pop, text=\"Ok\", command=self.cal)\n",
    "        self.button.pack(pady=5, side= TOP)\n",
    "\n",
    "\n",
    "    def calu(self):\n",
    "        self.sharp=[]\n",
    "        for i in self.region:\n",
    "            img=i.copy()\n",
    "            self.unsharped_img = unsharp_mask(img, radius=int(self.a.get()), amount=int(self.b.get()))\n",
    "            self.sharp.append(self.unsharped_img)\n",
    "            cv.imshow('output',self.unsharped_img)\n",
    "            cv.waitKey(0)\n",
    "            cv.destroyAllWindows()\n",
    "            self.pop.destroy()    \n",
    "\n",
    "    def sharp(self):\n",
    "\n",
    "        self.pop= Toplevel(self)\n",
    "        self.pop.geometry(\"400x400\")\n",
    "\n",
    "        Label(self.pop, text=\"Enter radius\", font=('Calibri 10')).pack()\n",
    "        self.a=Entry(self.pop, width=35)\n",
    "        self.a.insert(0, int(3))\n",
    "        self.a.pack()\n",
    "\n",
    "        Label(self.pop, text=\"Enter the amount\", font=('Calibri 10')).pack()\n",
    "        self.b=Entry(self.pop, width=35)\n",
    "        self.b.insert(0, int(1))\n",
    "        self.b.pack()\n",
    "\n",
    "        self.button= Button(self.pop, text=\"Ok\", command=self.calu)\n",
    "        self.button.pack(pady=5, side= TOP)\n",
    "\n",
    "\n",
    "\n",
    "    def OTSU_calculation(self,image):\n",
    "            self.n=int(self.z.get()) # number of clusters\n",
    "            thresholds = threshold_multiotsu(image, classes=self.n)\n",
    "            \n",
    "            # Digitize (segment) original image into multiple classes.\n",
    "            #np.digitize assign values 0, 1, 2, 3, ... to pixels in each class.\n",
    "            regions = np.digitize(image, bins=thresholds)\n",
    "            dic={}\n",
    "            for i in range(self.n):\n",
    "                a='seg'+str(i+1)\n",
    "                b=(regions == int(i))  # to create the different region number for every cluster\n",
    "                dic[a]=b\n",
    "            \n",
    "            \n",
    "            #We can use binary opening and closing operations to clean up. \n",
    "            #Open takes care of isolated pixels within the window\n",
    "            #Closing takes care of isolated holes within the defined window\n",
    "            di_open={}\n",
    "            di_close={}\n",
    "            for j in range(self.n):\n",
    "                c='seg'+str(j+1)+'_'+'opened'\n",
    "                e='seg'+str(j+1)\n",
    "                d=nd.binary_opening(dic[e], np.ones((3,3)))\n",
    "                di_open[c]=d\n",
    "                g='seg'+str(j+1)+'_'+'closed'\n",
    "                f=nd.binary_closing(di_open[c], np.ones((3,3)))\n",
    "                di_close[g]=f\n",
    "\n",
    "            all_segments_cleaned = np.zeros((image.shape[0], image.shape[1])) \n",
    "\n",
    "            \n",
    "            # here, we assign the each cluster white color with a region name and if we show lets say region 1 then in the\n",
    "            # image you will the cluster or region one with white color and the remainings are in black. This helps to visualize\n",
    "            # the clusters separately. \n",
    "            self.dic_show={}\n",
    "            i=0\n",
    "            for x, y in di_close.items():\n",
    "                all_segment=all_segments_cleaned.copy()\n",
    "                all_segment[y] = 255\n",
    "                ig= 'region'+str(i)\n",
    "                self.dic_show[ig]= all_segment\n",
    "                i+=1\n",
    "                \n",
    "                   \n",
    "            # when multiple images are there, in the GUI it will pop the first image only to the user\n",
    "            try:\n",
    "                if ((image==self.circle[0]).all()):             \n",
    "                    for x,y in self.dic_show.items():\n",
    "                        cv2.imshow(x, y)\n",
    "                    cv2.waitKey(0)\n",
    "                    cv2.destroyAllWindows()\n",
    "                \n",
    "            except AttributeError:\n",
    "                if ((image==self.blurr[0]).all()):\n",
    "                    for x,y in self.dic_show.items():\n",
    "                        cv2.imshow(x, y)\n",
    "                    cv2.waitKey(0)\n",
    "                    cv2.destroyAllWindows()\n",
    "                \n",
    "            except AttributeError:\n",
    "                if ((image==self.sharp[0]).all()):\n",
    "                    for x,y in self.dic_show.items():\n",
    "                        cv2.imshow(x, y)\n",
    "                    cv2.waitKey(0)\n",
    "                    cv2.destroyAllWindows()\n",
    "                     \n",
    "            self.region= all_segments_cleaned.reshape(image.shape) #All the noise should be cleaned now\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def OTSU(self):\n",
    "        try:\n",
    "            self.final_dict={}\n",
    "            c=0\n",
    "            for i in self.circle:\n",
    "                    image = i.copy()\n",
    "                    self.OTSU_calculation(image)\n",
    "                    self.final_dict[c]=self.dic_show\n",
    "                    c+=1\n",
    "                    \n",
    "            self.pop.destroy()\n",
    "                    \n",
    "\n",
    "        except AttributeError:\n",
    "            self.final_dict={}\n",
    "            c=0\n",
    "            for i in self.blurr:\n",
    "                image=i.copy()\n",
    "                self.OTSU_calculation(image)\n",
    "                self.final_dict[c]=self.dic_show\n",
    "                c+=1\n",
    "                \n",
    "            self.pop.destroy()\n",
    "\n",
    "        except AttributeError:\n",
    "            self.final_dict={}\n",
    "            c=0\n",
    "            for i in self.sharp:\n",
    "                image=i.copy()\n",
    "                self.OTSU_calculation(image)\n",
    "                self.final_dict[c]=self.dic_show\n",
    "                c+=1\n",
    "                \n",
    "            self.POP.destroy()\n",
    "\n",
    "\n",
    "    def K_value(self):\n",
    "\n",
    "            def K_value_graph():\n",
    "                img=self.region[0]\n",
    "                img2 = img.reshape((-1,1))\n",
    "\n",
    "                #gmm_model = GMM(2, covariance_type='tied').fit(img2)\n",
    "                #The above line generates GMM model for n=4\n",
    "                #Now let us call the bic method (or aic if you want).\n",
    "\n",
    "                #bic_value = gmm_model.bic(img2)  #Remember to call the same model name from above)\n",
    "                #You should see bic for GMM model generated using n=2.\n",
    "                #Do this exercise for different n values and plot them to find the minimum.\n",
    "\n",
    "\n",
    "                #Now, to explain m.bic, here are the lines I used in the video. \n",
    "                n_components = np.arange(3,8)\n",
    "                gmm_models = [GMM(n, covariance_type='tied').fit(img2) for n in n_components]\n",
    "                plt.plot(n_components, [m.bic(img2) for m in gmm_models], label='BIC')\n",
    "                f=Figure(figsize=(5,5),dpi=20)\n",
    "                canvas=FigureCanvasTkAgg(f,self)\n",
    "                #canvas.show()\n",
    "                #canvas.get_tk_widget().pack(side=tk.TOP,fill=tk.BOTH,expand=True)\n",
    "\n",
    "\n",
    "            def write_slogan():\n",
    "\n",
    "                self.pop= Toplevel(self)\n",
    "                self.pop.geometry(\"600x300\")\n",
    "\n",
    "                Label(self.pop, text=\"Enter K value\", font=('Calibri 10')).pack()\n",
    "                self.z=Entry(self.pop, width=30)\n",
    "                self.z.pack()\n",
    "\n",
    "                self.button= Button(self.pop, text=\"Show segemented image\", command=self.OTSU)\n",
    "                self.button.pack(pady=5, side= TOP)\n",
    "\n",
    "                self.button= Button(self.pop, text=\"Suggest K value\", command=K_value_graph)\n",
    "                self.button.pack(pady=5, side= TOP)\n",
    "\n",
    "\n",
    "            slogan = tk.Button(self,text=\"K_value\",command=write_slogan).place(x=10,y=70)\n",
    "\n",
    "\n",
    "\n",
    "    def segmentation_button(self):\n",
    "\n",
    "            def back(e):\n",
    "\n",
    "                  if self.comboExample.get() =='Multi OTSU': \n",
    "                                pass\n",
    "                  if self.comboExample.get() == 'K-means':\n",
    "                        pass\n",
    "                  if self.comboExample.get() == 'GMM':\n",
    "                        pass\n",
    "\n",
    "            self.labelpop = tk.Label(self,\n",
    "                            text = \"Choose the segmentation method \")\n",
    "\n",
    "            self.labelpop.place(x=80,y=65)\n",
    "            self.comboexample = ttk.Combobox(self, \n",
    "                                    values=[\n",
    "                                            \"Multi OTSU\", \n",
    "                                            \"K-means\",\n",
    "                                            \"GMM\",\n",
    "                                            ])\n",
    "            self.comboexample.place(x=85,y=90)\n",
    "\n",
    "            self.comboexample.bind(\"<<ComboboxSelected>>\", back)\n",
    "\n",
    "\n",
    "    def region_calculation(self):\n",
    "\n",
    "            def close():\n",
    "\n",
    "                self.POP.destroy()\n",
    "\n",
    "            def select_regions():\n",
    "\n",
    "                self.POP= Toplevel(self)\n",
    "                self.POP.geometry(\"300x300\")\n",
    "\n",
    "                Label(self.POP, text=\"Enter solderbale region\", font=('Calibri 10')).pack()\n",
    "                self.k=Entry(self.POP, width=20)\n",
    "                self.k.insert(0, int(0))\n",
    "                self.k.pack()\n",
    "\n",
    "                Label(self.POP, text=\"Enter void area\", font=('Calibri 10')).pack()\n",
    "                self.l=Entry(self.POP, width=20)\n",
    "                self.l.insert(0, int(1))\n",
    "                self.l.pack()\n",
    "\n",
    "                self.button= Button(self.POP, text=\"Ok\", command=close)\n",
    "                self.button.pack(pady=5, side= TOP)\n",
    "\n",
    "            slogan = tk.Button(self,text=\"Select regions for calculation\",command=select_regions).place(x=280,y=80)\n",
    "\n",
    "    \n",
    "    def voids_close(self,void_img,number):\n",
    "        #img1=img1.astype(np.float32)\n",
    "        \n",
    "        img1= cv.cvtColor(self.circle[number],cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "#         except AttributeError:\n",
    "            \n",
    "#             img1= cv.cvtColor(self.blurr[0],cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "#         except AttributeError:\n",
    "                \n",
    "#             img1= cv.cvtColor(self.sharp[0],cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "\n",
    "        #Threshold image to binary using OTSU. ALl thresholded pixels will be set to 255\n",
    "        #ret1, thresh = cv2.threshold(img, 100, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        all_segments_cleaned= void_img.copy()\n",
    "        thresh=   all_segments_cleaned.copy()\n",
    "\n",
    "        # Morphological operations to remove small noise - opening\n",
    "        #To remove holes we can use closing\n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        opening = cv.morphologyEx(thresh,cv.MORPH_OPEN,kernel, iterations = 5)\n",
    "\n",
    "        from skimage.segmentation import clear_border\n",
    "        opening = clear_border(opening) #Remove edge touching grains\n",
    "        #Check the total regions found before and after applying this. \n",
    "\n",
    "\n",
    "        #Now we know that the regions at the center of cells is for sure cells\n",
    "        #The region far away is background.\n",
    "        #We need to extract sure regions. For that we can use erode. \n",
    "        #But we have cells touching, so erode alone will not work. \n",
    "        #To separate touching objects, the best approach would be distance transform and then thresholding.\n",
    "\n",
    "        # let us start by identifying sure background area\n",
    "        # dilating pixes a few times increases cell boundary to background. \n",
    "        # This way whatever is remaining for sure will be background. \n",
    "        #The area in between sure background and foreground is our ambiguous area. \n",
    "        #Watershed should find this area for us. \n",
    "        sure_bg = cv.dilate(opening,kernel,iterations=5)\n",
    "\n",
    "\n",
    "        # Finding sure foreground area using distance transform and thresholding\n",
    "        #intensities of the points inside the foreground regions are changed to \n",
    "        #distance their respective distances from the closest 0 value (boundary).\n",
    "        #https://www.tutorialspoint.com/opencv/opencv_distance_transformation.htm\n",
    "        dist_transform = cv.distanceTransform(opening,cv.DIST_L2,3)\n",
    "\n",
    "        #Let us threshold the dist transform by 20% its max value.\n",
    "        #print(dist_transform.max()) gives about 21.9\n",
    "        ret2, sure_fg = cv.threshold(dist_transform,0.2*dist_transform.max(),255,0)\n",
    "\n",
    "        #0.2* max value seems to separate the cells well.\n",
    "        #High value like 0.5 will not recognize some grain boundaries.\n",
    "\n",
    "        # Unknown ambiguous region is nothing but bkground - foreground\n",
    "        sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "        unknown = cv.subtract(sure_bg,sure_fg)\n",
    "\n",
    "        #Now we create a marker and label the regions inside. \n",
    "        # For sure regions, both foreground and background will be labeled with positive numbers.\n",
    "        # Unknown regions will be labeled 0. \n",
    "        #For markers let us use ConnectedComponents. \n",
    "        #ret3, markers = cv2.connectedComponents(sure_fg)\n",
    "        connectivity=8\n",
    "        n_labels, markers, stats, centroids = cv.connectedComponentsWithStats(sure_fg,\n",
    "                                                                              connectivity,cv.CV_32S)\n",
    "\n",
    "         # Create false color image\n",
    "        colors = np.random.randint(0, 255, size=(n_labels , 3), dtype=np.uint8)\n",
    "        colors[0] = [0, 0, 0]  # for cosmetic reason we want the background black\n",
    "        false_colors = colors[markers]\n",
    "        #One problem rightnow is that the entire background pixels is given value 0.\n",
    "        #This means watershed considers this region as unknown.\n",
    "        #So let us add 10 to all labels so that sure background is not 0, but 10\n",
    "        markers = markers+10\n",
    "\n",
    "        # Now, mark the region of unknown with zero\n",
    "        markers[unknown==255] = 0\n",
    "        #plt.imshow(markers, cmap='jet')   #Look at the 3 distinct regions.\n",
    "        markers = markers.astype('int32')\n",
    "        #markers = markers.astype(np.uint8)\n",
    "        #Now we are ready for watershed filling. \n",
    "        markers = cv.watershed(img1,markers)\n",
    "        #The boundary region will be marked -1\n",
    "        #https://docs.opencv.org/3.3.1/d7/d1b/group__imgproc__misc.html#ga3267243e4d3f95165d55a618c65ac6e1\n",
    "\n",
    "\n",
    "        #Let us color boundaries in yellow. OpenCv assigns boundaries to -1 after watershed.\n",
    "        img1[markers == -1] = [255,255,255]  \n",
    "\n",
    "        img2 = color.label2rgb(markers, bg_label=0)\n",
    "        markers = markers.astype(np.uint8)\n",
    "#         cv2.imshow('marker', markers)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "        return markers,img2\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def watershed(self):\n",
    "\n",
    "        img=(list((self.final_dict).values()))[0] # it gets the first image in order to help the user to fix the watershed algorithm parameters\n",
    "        void_img=(list((img).values()))[(int(self.l.get()))] # get the region having the voids\n",
    "        void_img=void_img.astype(np.uint8)\n",
    "        loc=0\n",
    "        markers,img2=self.voids_close(void_img,loc) # apply watershed algorithm on the region having voids\n",
    "        cv2.imshow('Colored Grains', img2)\n",
    "        cv2.imshow('marker', markers)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def watershed_values(self):\n",
    "\n",
    "            def closing():\n",
    "                \n",
    "                all_img=(list((self.final_dict).values())) # get the all regions of every segmented images \n",
    "                \n",
    "                for j in range (len(all_img)): # iterate over all the images\n",
    "                    \n",
    "                    no=j\n",
    "                    each_img = all_img[j].copy() # here j defines the image number\n",
    "                    \n",
    "                    void_img=(list((each_img).values()))[(int(self.l.get()))] # get the region having void of the j number image\n",
    "                    \n",
    "                    void_img=void_img.astype(np.uint8)\n",
    "                    \n",
    "                    reference_area_img=(list((each_img).values()))[(int(self.k.get()))] # get the region having solderable of the j number image\n",
    "                    \n",
    "                    reference_area_img=reference_area_img.astype(np.uint8)\n",
    "                    \n",
    "                    markers_void,img2_void=self.voids_close(void_img,no) # apply watershe3d algorithm on void region\n",
    "                    \n",
    "                    markers_reference,img2_reference=self.voids_close(reference_area_img,no) # apply watershe3d algorithm on solderable region\n",
    "                    \n",
    "                    props_voids_watershed_void = measure.regionprops_table( markers_void,  # calculate the properties of surfaces in the void region\n",
    "                          properties=['label',\n",
    "                                      'area',\n",
    "                                      'eccentricity','centroid','perimeter'])\n",
    "\n",
    "                    pd.set_option('display.max_rows', None)\n",
    "                    df_markers_void = pd.DataFrame(props_voids_watershed_void)\n",
    "                    \n",
    "                    props_voids_watershed_reference = measure.regionprops_table(markers_reference,  # calculate the properties of surfaces in the solderable region\n",
    "                          properties=['label',\n",
    "                                      'area',\n",
    "                                      'centroid'])\n",
    "\n",
    "                    pd.set_option('display.max_rows', None)\n",
    "                    df_markers_reference = pd.DataFrame(props_voids_watershed_reference)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "        \n",
    "                    \n",
    "                    min_ecen = (float(self.x.get())) # minimum circularity defined for calculating the area of the voids\n",
    "                    void_area=0\n",
    "                    false_colors_draw_watershed_void =img2_void.copy()\n",
    "                    for i ,(x1,y1,eccen,ar,per) in enumerate (zip(df_markers_void['centroid-1'], df_markers_void['centroid-0'],df_markers_void['eccentricity'],df_markers_void['area'],df_markers_void['perimeter'])):\n",
    "                            p=((12.56)*ar)/(per**2) # calculating the circulating \n",
    "                            if p> min_ecen:\n",
    "                                void_area=void_area+ar\n",
    "                                formatted_string = \"{:.2f}\".format(ar)\n",
    "                                cv2.drawMarker(false_colors_draw_watershed_void, (int(x1), int(y1)),\n",
    "                                color=(255, 255, 255), markerType=cv2.MARKER_CROSS)\n",
    "                                cv2.putText(false_colors_draw_watershed_void, str(formatted_string), (int(x1), int(y1)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "                                \n",
    "                    false_colors_draw_watershed_reference =img2_reference.copy()\n",
    "                    ref_ar=0\n",
    "                    for j ,(x2,y2,are) in enumerate (zip(df_markers_reference['centroid-1'], df_markers_reference['centroid-0'],df_markers_reference['area'])):\n",
    "                        \n",
    "                            #if p> min_ecen:\n",
    "                                ref_ar=ref_ar+are\n",
    "                                #void_area=void_area+ar\n",
    "                                formatted = \"{:.2f}\".format(are)\n",
    "                                cv2.drawMarker(false_colors_draw_watershed_reference, (int(x2), int(y2)),\n",
    "                                color=(255, 255, 255), markerType=cv2.MARKER_CROSS)\n",
    "                                cv2.putText(false_colors_draw_watershed_reference, str(formatted), (int(x2), int(y2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "                                \n",
    "                    \n",
    "                    #print(ref_ar)\n",
    "                    cv2.imshow('marker', false_colors_draw_watershed_reference)\n",
    "                    \n",
    "                    #cv2.destroyAllWindows()\n",
    "                    \n",
    "                    cv2.imshow('void', false_colors_draw_watershed_void)\n",
    "                    cv2.waitKey(0)\n",
    "                    cv2.destroyAllWindows()\n",
    "                    \n",
    "        \n",
    "                    f = Figure(figsize=(20, 20))\n",
    "                    a = f.add_subplot(111)\n",
    "                    a.imshow(false_colors_draw_watershed_void)\n",
    "                    \n",
    "                    canvas = FigureCanvasTkAgg(f, master=self.TOP)\n",
    "                    canvas.get_tk_widget().pack(side=\"top\", fill=\"both\", expand=1)\n",
    "                    canvas._tkcanvas.pack(side=\"top\", fill=\"both\", expand=1)\n",
    "#                     f,(ax1)= plt.subplots(1,1,figsize=(20,20))\n",
    "                    \n",
    "#                     ax1.set_title('false_colors watershed')\n",
    "#                     ax1.imshow(false_colors_draw_watershed)\n",
    "                \n",
    "                    solderable_area= (df_markers_reference['area'].sum())\n",
    "                    \n",
    "                    print(solderable_area)\n",
    "                    print(void_area)\n",
    "                    void_percentage=((void_area)/ (solderable_area+void_area))\n",
    "                    print(void_percentage)\n",
    "                    \n",
    "        \n",
    "                #self.TOP.destroy()\n",
    "                \n",
    "\n",
    "            def values():\n",
    "\n",
    "                self.TOP= Toplevel(self)\n",
    "                self.TOP.geometry(\"600x600\")\n",
    "\n",
    "                Label(self.TOP, text=\"Enter Number of Iteration\", font=('Calibri 10')).pack()\n",
    "                self.o=Entry(self.TOP, width=20)\n",
    "                self.o.insert(0, int(5))\n",
    "                self.o.pack()\n",
    "\n",
    "                Label(self.TOP, text=\"Enter distance\", font=('Calibri 10')).pack()\n",
    "                self.p=Entry(self.TOP, width=20)\n",
    "                self.p.insert(0, float(0.20))\n",
    "                self.p.pack()\n",
    "                \n",
    "                Label(self.TOP, text=\"Enter solderbale region\", font=('Calibri 10')).pack()\n",
    "                self.k=Entry(self.TOP, width=20)\n",
    "                self.k.insert(0, int(0))\n",
    "                self.k.pack()\n",
    "\n",
    "                Label(self.TOP, text=\"Enter void area\", font=('Calibri 10')).pack()\n",
    "                self.l=Entry(self.TOP, width=20)\n",
    "                self.l.insert(0, int(1))\n",
    "                self.l.pack()\n",
    "                \n",
    "                Label(self.TOP, text=\"Enter K value\", font=('Calibri 10')).pack()\n",
    "                self.z=Entry(self.TOP, width=20)\n",
    "                self.z.pack()\n",
    "                \n",
    "                Label(self.TOP, text=\"Enter circularity value\", font=('Calibri 10')).pack()\n",
    "                self.x=Entry(self.TOP, width=20)\n",
    "                self.x.pack()\n",
    "\n",
    "                self.button= Button(self.TOP, text=\"Show image\", command=self.watershed)\n",
    "                self.button.pack(pady=5, side= TOP)\n",
    "\n",
    "\n",
    "                self.button= Button(self.TOP, text=\"Ok\", command=closing)\n",
    "                self.button.pack(pady=5, side= TOP)\n",
    "\n",
    "            slogan = tk.Button(self,text=\"Values for void closing (watershed) \",command=values).place(x=280,y=80)\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373305\n",
      "53238\n",
      "0.12481273869223032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373305\n",
      "47885\n",
      "0.11368978370806525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373305\n",
      "41774\n",
      "0.1006410827818319\n"
     ]
    }
   ],
   "source": [
    "abc= segmentation()\n",
    "abc.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
